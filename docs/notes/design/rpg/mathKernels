TODO (rpg GPU code):

Clean up of simple vector linear algebra kernel functions
----------------------------------------------------------

1) Create a new public branch vector in which to do clean up.
   Submit partial but functional changes to that.

2) Comment out (first) then erase (second) unused kernels.
   Some are found in solvers/Block.tpp and (possibly?) math/Helpers.cu
   (From Ryan: definitely some in math/Helpers.cu!)

3) Analyze what operations in the current rpg code are or should be 
   implemented by calling a standard linear algebra operation like
   one of those described below. That will give a list of operations
   that are needed immediately, and may identify some possible 
   operations that we actually don't need immediately. 

4) Establish more consistent function name conventions for a new
   set of functions in pscf/cuda/LinearAlgebra files.

   Proposal: One way to do this would be to write and test copies 
   with new names and/or new interfaces, and then just start 
   replacing function calls to refer to the new functions. Comment 
   out and remove old ones only after all calls have been changed

   Proposal for name convention (current preference):

          Use overloading of arguments to distinguish input types,
          thus limiting the number of required function names.

          Use add, sub, mul div for binary operations. Start each
          function name with the binary operation in lower case.

          Use V for vector, S for scalar for input argument(s). 
          Agument types V and S follow the operation name. The
          function addVV thus implements vector-vector addition.

          Multiplication and division are interpreted as elementwise
          operations, like addition and subtraction.

          Use Eq after the operation name to denote in-place operation 
          (compound assignments), such as addEq, analogous to C/C++
          notation +=, -=, *=, 

          In examples below (but not in names) use upper case for 
          vectors, lower case for scalars:

            addVV   :  A = B + C vector-vector addition
            addVS   :  A = B + c vector-scalar addition
            addEqVV :  A = A + B in-place vector-vector addition
            addEqVS :  A = A + c in-place vector-scalar addition

          Result types are known from argument types.
          Binary operations involving inputs of the same type (both
          cudaReal or both cudaComplex) yield a result of that type.  
          Operations involving complex and real arguments yield 
          complex results. 
 
          For in place operation, the first argument must be a vector
          of the same type as the result, passed as a pointer.
         
          C interface: Order of the first few parameters would be the 
          same as in order of equation, with the LHS vector listed 
          first.  Int array size would be after arguments.

          Define function in Pscf::Cuda.

          Examples of interfaces:

            addVV(real* result, real const * a, real const * b, int n)
            addVV(complex* result, complex const * a, complex const * b, int n)
            addVV(complex* result, complex* a, real const * b, in n)
  
            addVS(real* result, real const * a, real b, int n)
            addVS(complex* result, complex const * a, complex b, int n)
            addVS(complex* result, complex const * a, real b, int n)
            addVS(complex* result, real const * a, complex b, int n)
  
            addEqVV(real* a, real const * b, int n)
            addEqVV(complex* a, complex const * b, int n)
            addEqVV(complex* a, real const * b, int n)
  
            addEqVS(real* a, real b, int n)
            addEqVS(complex* a, complex b, int n)
            addEqVS(complex* a, real b, int n)
     
          Here "real" and  "complex" denote cudaReal and cudaComplex.

          That is a total of 13 functions. With 4 possible operations,
          that is 52 possible functions. Start by implementing the ones
          we need now.

   Older proposal (less desirable, I think):

       LHS (result):
       rV - real vector
       cV - complex vector

       Pointwise binary Operations:
       Sub   -> subtraction
       Add   -> addition
       Mul   -> pointwise multiplication
       Div   -> pointwise division

       Assignment:
       Eq     -> assignment
       Eq(Op) -> assignment to first vector operand

       RHS operands:
       V   -> vector on rhs (same as LHS by default)
       R   -> real vector with same value for all elements
       C   -> complex Vector with same value for all elements
       r   -> real prefactor multiplying all elements
       c   -> complex prefactor multiplying all elements
       Vr  -> Vector multiplied by real prefactor
       Vc  -> Vector multiplied by complex prefactor

       In what follows: A, B, C are vectors, while a, b are scalars 

       Simple Assignment:

       C = A        :  rV_EqV   (vector assignment)
       C = R        :  rV_EqR   (assign all elements same value)

       Pointwise Binary operations C = A Op B have form C_OpAB 
       (two arguments)

       C = A + B    :  rV_AddVV
       C = A - B    :  rV_SubVV
       C = A + R    :  rV_AddVR
       C = A - R    :  rV_SubVR
       C = A * B    :  rV_MulVV   (element-wise multiplication)
       C = A / B    :  rV_DivVV   (element-wise division)
       C = Aa + Bb  :  rV_AddVrVr
       C = A + Bb   :  rV_AddVVr

       Increment operations A = A Op B have form A_EqOpB 
       (First operand must be a vector, same address as the LHS)

       A = A + B    :  rV_EqAddV
       A = A - B    :  rV_EqSubV
       A = A + R    :  rV_EqAddR (pointwise add same value to all elements)
       A = A - R    :  rV_EqSubR (pointwise sub same value from all)
       A = A*r      :  rV_EqMulr
       A = A + aB   :  rV_EqAddVr

       Corresponding functions that return a complex-valued vector
       will start with cV. Arguments on the RHS side will use V for
       a complex vector, c for a complex scalar that multiplies a
       vector, r for a real scalar that multiplies a vector, C for 
       a complex vector with the same value for all elements, R for 
       a real vector with the same value for all elements. If we 
       need a symbol for a real valued vector (which we may not)
       use U. 

       Rr  -> real vector (capital) and scalar (lower case)
       Cc  -> complex vector (capital) and scalar (lower case)

5) Kernels vs. C++ Wrapper functions

       For many required operations with vector results, we will probably 
       want three types of closely related function:

       1. A global cuda kernel like the existing kernels, in which the 
          Block and Thread counts have to be passed explicitly. This 
          could be defined in pscf/cuda. Arrays are passed as pointers.

       2. A C++ function in which a ThreadGrid is passed as an argument, 
          along with bare C pointers to memory on the GPU, and an array 
          dimension.  This would call a kernel internally. The presence 
          of a ThreadGrid in the argument would distinguish the interface 
          from that of an analogous kernel, so the name could be the same. 
          This could also be defined in pscf/cuda

       3. A C++ function that takes RField or RFieldDft containers.
          This would calls the C++ pointer version internally. This could 
          take a ThreadGrid as an argument or create one internally from 
          knowledge of field array dimensions. The interface would be 
          distinguished from that of the other two function types by the 
          appearance of container types rather than pointers. This would 
          have to be defined in a file in prdc/gpu, since that is where 
          the containers are defined.

       - Even the existing rpg code might be able to use some functions 
         that act on complex-valued data in order to operator on RFieldDft 
         containers.  We'd have to think about something that operates on 
         RFieldDft containers could use the same underlying kernels as 
         something that operates on a CField container (not yet created). 
         It depends in part on what data types cudaFFT is using for these 
         two types of data.

       - Container CField would be created in prdc/cuda and prdc/cpu

       - We would later add functions that act on complex data to 
         pscf/gpu/linearAlgebra, and analogous functions that act on 
         CField containers to prdc/gpu

       - We need thorough unit tests to be written for all functions 
         during development of these functions. These are simple, but 
         humans still make mistakes, and its a lot of minor changes at 
         once. 

6) Find locally defined kernels and replace them one-by-one with ones 
defined in pscf/gpu or prdc/gpu:

     - Replace scaleRealData in fieldFFT.tpp 

     - Consider replacing some pointwise multiplication functions defined 
       in Block.

     - Consider replacing FFTBatched.tpp/scaleComplexData 

--------------------------------------------------------------------------
Parallel Reductions:

   After cleaning up operations that create or modify vectors, we could
   try to clean up parallel reduction kernels and wrappers.

1) Move parallel reduction kernels to private namespace in implementation
   of kernel wrappers, so not publically visible. 

    Example wrapper function for reductions:

       reduceSum
       reduceAbsMax

       Overloaded versions of wrappers for pointers and containers,
       as for vector operations. Pointer versions should take a 
       ThreadGrid as an argument.

       Some convention will be need to distinguish names of kernels
       from analogous C++ wrapper. The use of a ThreadGrid argument
       to the C++ wrapper may be enough, if done consistently. 

2) Rename some files:

       KernelWrappers -> Reductions (both kernels and C++ wrappers)

       Provide overloaded operations for field containers in 
       directories or files that define containers

       Move Helpers to pscf/gpu
      
